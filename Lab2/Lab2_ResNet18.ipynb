{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms, models\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.utils.data as data\n",
    "import torchvision.utils as utils\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset path\n",
    "data_path_train = \"./data/training\"\n",
    "data_path_test = \"./data/testing\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset ImageFolder\n",
      "    Number of datapoints: 1646\n",
      "    Root location: ./data/training\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               Resize(size=(224, 224), interpolation=bilinear, max_size=None, antialias=warn)\n",
      "               ToTensor()\n",
      "           )\n",
      "{'Baked Potato': 0, 'Crispy Chicken': 1, 'Donut': 2, 'Fries': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/NFS/opt/anaconda3/envs/ml2023f/lib/python3.8/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    }
   ],
   "source": [
    "# data transform, you can add different transform methods and resize image to any size\n",
    "img_size = 224\n",
    "transform = transforms.Compose([\n",
    "                       transforms.Resize((img_size,img_size)),\n",
    "                       transforms.ToTensor()\n",
    "                       ])\n",
    "\n",
    "#build dataset\n",
    "dataset = datasets.ImageFolder(root=data_path_train,transform=transform)\n",
    "\n",
    "# spilt your data into train and val\n",
    "TOTAL_SIZE = len(dataset)\n",
    "ratio = 0.9\n",
    "train_len = round(TOTAL_SIZE * ratio)\n",
    "valid_len = round(TOTAL_SIZE * (1-ratio))\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_len, valid_len])\n",
    "\n",
    "#build dataloader\n",
    "train_data_loader = data.DataLoader(train_dataset, batch_size=32, shuffle=True,  num_workers=4)\n",
    "val_data_loader = data.DataLoader(val_dataset, batch_size=32, shuffle=True,  num_workers=4)\n",
    "\n",
    "#check dataset\n",
    "print(dataset)\n",
    "print(dataset.class_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train function\n",
    "def train(model, criterion, optimizer):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    total_correct = 0\n",
    "    \n",
    "    # Iterate over data\n",
    "    for inputs, labels in train_data_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad() # Be sure to add and thoroughly clean the previous gradient.\n",
    "\n",
    "        # forward\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # backward + optimize\n",
    "        loss.backward()  # Get gradient of the whole model by loss function\n",
    "        optimizer.step() # Update weight\n",
    "\n",
    "        # statistics\n",
    "        total_loss += loss.item()\n",
    "        total_correct += torch.sum(preds == labels.data)\n",
    "        \n",
    "    avg_loss = total_loss / len(train_data_loader)\n",
    "    accuracy = total_correct.double() / len(train_dataset) * 100\n",
    "\n",
    "    print('Training Accuracy: {:.4f}% Training Loss: {:.4f}'.format(accuracy, avg_loss))\n",
    "    return \n",
    "\n",
    "#validation function\n",
    "def valid(model, criterion):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    total_correct = 0\n",
    "    \n",
    "    # Iterate over data\n",
    "    for inputs, labels in val_data_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # forward\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # statistics\n",
    "        total_loss += loss.item()\n",
    "        total_correct += torch.sum(preds == labels.data)\n",
    "        \n",
    "    avg_loss = total_loss / len(val_data_loader)\n",
    "    accuracy = total_correct.double() / len(val_dataset) * 100\n",
    "\n",
    "    print('Validation Accuracy: {:.4f}% Validation Loss: {:.4f}'.format(accuracy, avg_loss))\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using gpu if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "#build your model here\n",
    "class RN18BasicBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride):\n",
    "        super(RN18BasicBlock, self).__init__()\n",
    "        self.layer = nn.Sequential(\n",
    "            nn.Conv2d(in_channels , out_channels, kernel_size = 3, stride = stride, padding = 1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size = 3, stride = 1, padding = 1),\n",
    "            nn.BatchNorm2d(out_channels)\n",
    "        )\n",
    "\n",
    "        self.extra = nn.Sequential()\n",
    "        if in_channels != out_channels:\n",
    "            self.extra = nn.Sequential(\n",
    "                nn.Conv2d(in_channels , out_channels, kernel_size = 1, stride = stride),\n",
    "                nn.BatchNorm2d(out_channels),\n",
    "            )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out  = self.layer(x)\n",
    "        out2 = self.extra(x)\n",
    "        return F.relu(out + out2)\n",
    "\n",
    "class RN18(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RN18, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size = 7, stride = 2, padding = 3),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.MaxPool2d(kernel_size = 3, stride = 2, padding = 1),\n",
    "            RN18BasicBlock(64,64,1),\n",
    "            RN18BasicBlock(64,64,1)\n",
    "        )\n",
    "\n",
    "        self.conv3 = nn.Sequential(\n",
    "            RN18BasicBlock(64 ,128,2),\n",
    "            RN18BasicBlock(128,128,1)\n",
    "        )\n",
    "\n",
    "        self.conv4 = nn.Sequential(\n",
    "            RN18BasicBlock(128,256,2),\n",
    "            RN18BasicBlock(256,256,1)\n",
    "        )\n",
    "\n",
    "        self.conv5 = nn.Sequential(\n",
    "            RN18BasicBlock(256,512,2),\n",
    "            RN18BasicBlock(512,512,1)\n",
    "        )\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512,4)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.conv2(out)\n",
    "        out = self.conv3(out)\n",
    "        out = self.conv4(out)\n",
    "        out = self.conv5(out)\n",
    "        out = self.avgpool(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "#call model\n",
    "model = RN18()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------start training--------------\n",
      "epoch: 1\n",
      "Training Accuracy: 48.0081% Training Loss: 1.3345\n",
      "Validation Accuracy: 49.6970% Validation Loss: 1.4137\n",
      "model saved\n",
      "epoch: 2\n",
      "Training Accuracy: 60.4997% Training Loss: 0.9528\n",
      "Validation Accuracy: 44.8485% Validation Loss: 1.4230\n",
      "epoch: 3\n",
      "Training Accuracy: 63.3356% Training Loss: 0.9478\n",
      "Validation Accuracy: 54.5455% Validation Loss: 1.1062\n",
      "model saved\n",
      "epoch: 4\n",
      "Training Accuracy: 65.4963% Training Loss: 0.8397\n",
      "Validation Accuracy: 63.0303% Validation Loss: 0.9241\n",
      "model saved\n",
      "epoch: 5\n",
      "Training Accuracy: 70.3579% Training Loss: 0.7815\n",
      "Validation Accuracy: 61.8182% Validation Loss: 1.0401\n",
      "epoch: 6\n",
      "Training Accuracy: 70.1553% Training Loss: 0.7767\n",
      "Validation Accuracy: 60.6061% Validation Loss: 1.1955\n",
      "epoch: 7\n",
      "Training Accuracy: 72.0459% Training Loss: 0.7132\n",
      "Validation Accuracy: 67.8788% Validation Loss: 0.7812\n",
      "model saved\n",
      "epoch: 8\n",
      "Training Accuracy: 74.6793% Training Loss: 0.6662\n",
      "Validation Accuracy: 68.4848% Validation Loss: 0.8321\n",
      "model saved\n",
      "epoch: 9\n",
      "Training Accuracy: 76.6374% Training Loss: 0.6115\n",
      "Validation Accuracy: 71.5152% Validation Loss: 0.7167\n",
      "model saved\n",
      "epoch: 10\n",
      "Training Accuracy: 77.7853% Training Loss: 0.5958\n",
      "Validation Accuracy: 63.6364% Validation Loss: 0.8254\n",
      "epoch: 11\n",
      "Training Accuracy: 78.7981% Training Loss: 0.5773\n",
      "Validation Accuracy: 69.6970% Validation Loss: 0.8926\n",
      "epoch: 12\n",
      "Training Accuracy: 77.1776% Training Loss: 0.6009\n",
      "Validation Accuracy: 69.0909% Validation Loss: 0.8928\n",
      "epoch: 13\n",
      "Training Accuracy: 81.4990% Training Loss: 0.5258\n",
      "Validation Accuracy: 64.2424% Validation Loss: 1.3882\n",
      "epoch: 14\n",
      "Training Accuracy: 79.8109% Training Loss: 0.5153\n",
      "Validation Accuracy: 49.0909% Validation Loss: 1.6473\n",
      "epoch: 15\n",
      "Training Accuracy: 80.6212% Training Loss: 0.5728\n",
      "Validation Accuracy: 71.5152% Validation Loss: 0.7106\n",
      "model saved\n",
      "epoch: 16\n",
      "Training Accuracy: 81.0939% Training Loss: 0.5309\n",
      "Validation Accuracy: 60.6061% Validation Loss: 1.1596\n",
      "epoch: 17\n",
      "Training Accuracy: 81.8366% Training Loss: 0.4859\n",
      "Validation Accuracy: 72.7273% Validation Loss: 0.6242\n",
      "model saved\n",
      "epoch: 18\n",
      "Training Accuracy: 83.7272% Training Loss: 0.4665\n",
      "Validation Accuracy: 78.1818% Validation Loss: 0.6967\n",
      "model saved\n",
      "epoch: 19\n",
      "Training Accuracy: 83.7947% Training Loss: 0.4423\n",
      "Validation Accuracy: 76.3636% Validation Loss: 0.6834\n",
      "epoch: 20\n",
      "Training Accuracy: 85.6178% Training Loss: 0.4210\n",
      "Validation Accuracy: 75.7576% Validation Loss: 0.6921\n",
      "epoch: 21\n",
      "Training Accuracy: 84.1323% Training Loss: 0.4449\n",
      "Validation Accuracy: 78.1818% Validation Loss: 0.6300\n",
      "model saved\n",
      "epoch: 22\n",
      "Training Accuracy: 85.6853% Training Loss: 0.3798\n",
      "Validation Accuracy: 70.3030% Validation Loss: 0.9342\n",
      "epoch: 23\n",
      "Training Accuracy: 85.7529% Training Loss: 0.3968\n",
      "Validation Accuracy: 81.2121% Validation Loss: 0.5151\n",
      "model saved\n",
      "epoch: 24\n",
      "Training Accuracy: 87.1033% Training Loss: 0.3908\n",
      "Validation Accuracy: 80.0000% Validation Loss: 0.6800\n",
      "epoch: 25\n",
      "Training Accuracy: 87.4409% Training Loss: 0.3666\n",
      "Validation Accuracy: 77.5758% Validation Loss: 0.6783\n",
      "epoch: 26\n",
      "Training Accuracy: 86.9007% Training Loss: 0.3853\n",
      "Validation Accuracy: 78.1818% Validation Loss: 0.8734\n",
      "epoch: 27\n",
      "Training Accuracy: 88.9264% Training Loss: 0.3204\n",
      "Validation Accuracy: 69.6970% Validation Loss: 1.1667\n",
      "epoch: 28\n",
      "Training Accuracy: 85.2802% Training Loss: 0.4182\n",
      "Validation Accuracy: 69.6970% Validation Loss: 0.8783\n",
      "epoch: 29\n",
      "Training Accuracy: 86.8332% Training Loss: 0.3791\n",
      "Validation Accuracy: 69.0909% Validation Loss: 0.8892\n",
      "epoch: 30\n",
      "Training Accuracy: 87.7110% Training Loss: 0.3575\n",
      "Validation Accuracy: 70.9091% Validation Loss: 0.7876\n",
      "epoch: 31\n",
      "Training Accuracy: 88.4537% Training Loss: 0.3429\n",
      "Validation Accuracy: 67.8788% Validation Loss: 0.9861\n",
      "epoch: 32\n",
      "Training Accuracy: 90.3444% Training Loss: 0.2815\n",
      "Validation Accuracy: 76.3636% Validation Loss: 0.6833\n",
      "epoch: 33\n",
      "Training Accuracy: 87.5760% Training Loss: 0.3273\n",
      "Validation Accuracy: 75.1515% Validation Loss: 0.6057\n",
      "epoch: 34\n",
      "Training Accuracy: 87.2384% Training Loss: 0.3661\n",
      "Validation Accuracy: 77.5758% Validation Loss: 0.6941\n",
      "epoch: 35\n",
      "Training Accuracy: 87.1033% Training Loss: 0.3450\n",
      "Validation Accuracy: 78.7879% Validation Loss: 0.7315\n",
      "epoch: 36\n",
      "Training Accuracy: 88.4537% Training Loss: 0.3182\n",
      "Validation Accuracy: 73.3333% Validation Loss: 0.8705\n",
      "epoch: 37\n",
      "Training Accuracy: 89.1290% Training Loss: 0.3059\n",
      "Validation Accuracy: 76.3636% Validation Loss: 0.7610\n",
      "epoch: 38\n",
      "Training Accuracy: 89.8042% Training Loss: 0.2898\n",
      "Validation Accuracy: 78.1818% Validation Loss: 0.6685\n",
      "epoch: 39\n",
      "Training Accuracy: 89.6016% Training Loss: 0.2800\n",
      "Validation Accuracy: 81.2121% Validation Loss: 0.5999\n",
      "model saved\n",
      "epoch: 40\n",
      "Training Accuracy: 91.2221% Training Loss: 0.2569\n",
      "Validation Accuracy: 81.8182% Validation Loss: 0.5854\n",
      "model saved\n",
      "epoch: 41\n",
      "Training Accuracy: 92.8427% Training Loss: 0.2103\n",
      "Validation Accuracy: 78.7879% Validation Loss: 0.7865\n",
      "epoch: 42\n",
      "Training Accuracy: 92.5726% Training Loss: 0.2202\n",
      "Validation Accuracy: 75.7576% Validation Loss: 1.0969\n",
      "epoch: 43\n",
      "Training Accuracy: 92.8427% Training Loss: 0.1871\n",
      "Validation Accuracy: 80.6061% Validation Loss: 0.7171\n",
      "epoch: 44\n",
      "Training Accuracy: 93.0452% Training Loss: 0.1943\n",
      "Validation Accuracy: 83.0303% Validation Loss: 0.7128\n",
      "model saved\n",
      "epoch: 45\n",
      "Training Accuracy: 92.3025% Training Loss: 0.2333\n",
      "Validation Accuracy: 72.1212% Validation Loss: 1.4520\n",
      "epoch: 46\n",
      "Training Accuracy: 91.8298% Training Loss: 0.2214\n",
      "Validation Accuracy: 75.1515% Validation Loss: 1.0105\n",
      "epoch: 47\n",
      "Training Accuracy: 93.1803% Training Loss: 0.1954\n",
      "Validation Accuracy: 79.3939% Validation Loss: 0.6112\n",
      "epoch: 48\n",
      "Training Accuracy: 93.7880% Training Loss: 0.1697\n",
      "Validation Accuracy: 79.3939% Validation Loss: 0.5888\n",
      "epoch: 49\n",
      "Training Accuracy: 94.3957% Training Loss: 0.1575\n",
      "Validation Accuracy: 80.0000% Validation Loss: 0.7070\n",
      "epoch: 50\n",
      "Training Accuracy: 94.3957% Training Loss: 0.1546\n",
      "Validation Accuracy: 80.0000% Validation Loss: 1.2040\n"
     ]
    }
   ],
   "source": [
    "####################  implement your optimizer ###################################\n",
    "## you can use any training methods if you want (ex:lr decay, weight decay.....)\n",
    "learning_rate = 0.001\n",
    "epochs = 50\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate, betas = (0.99,0.999), weight_decay = 0.00001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "# start training\n",
    "model.to(device=device)\n",
    "acc_best = 0.0\n",
    "\n",
    "print('--------------start training--------------')\n",
    "for epoch in range(1, epochs+1):\n",
    "    \n",
    "    print('epoch:', epoch)\n",
    "    train(model, criterion, optimizer)\n",
    "    accuracy = valid(model, criterion)\n",
    "    \n",
    "    if accuracy >= acc_best:\n",
    "        acc_best = accuracy\n",
    "        print(\"model saved\")\n",
    "        # save the model\n",
    "        torch.save(model, \"model.pth\")\n",
    "    learning_rate *= 0.9"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
