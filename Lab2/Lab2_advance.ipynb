{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms, models\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.utils.data as data\n",
    "import torchvision.utils as utils\n",
    "import os\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset path\n",
    "data_path_train = \"data/training\"\n",
    "data_path_test = \"data/testing\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset ImageFolder\n",
      "    Number of datapoints: 1646\n",
      "    Root location: data/training\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               Resize(size=(224, 224), interpolation=bilinear, max_size=None, antialias=warn)\n",
      "               ToTensor()\n",
      "           )\n",
      "{'Baked Potato': 0, 'Crispy Chicken': 1, 'Donut': 2, 'Fries': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/NFS/opt/anaconda3/envs/ml2023f/lib/python3.8/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    }
   ],
   "source": [
    "# data transform, you can add different transform methods and resize image to any size\n",
    "img_size = 224\n",
    "transform = transforms.Compose([\n",
    "                       transforms.Resize((img_size,img_size)),\n",
    "                       transforms.ToTensor()\n",
    "                       ])\n",
    "\n",
    "\n",
    "#build dataset\n",
    "dataset = datasets.ImageFolder(root=data_path_train,transform=transform)\n",
    "\n",
    "# spilt your data into train and val\n",
    "TOTAL_SIZE = len(dataset)\n",
    "ratio = 0.9\n",
    "train_len = round(TOTAL_SIZE * ratio)\n",
    "valid_len = round(TOTAL_SIZE * (1-ratio))\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_len, valid_len])\n",
    "\n",
    "#build dataloader\n",
    "train_data_loader = data.DataLoader(train_dataset, batch_size=8, shuffle=True,  num_workers=4)\n",
    "val_data_loader = data.DataLoader(val_dataset, batch_size=8, shuffle=True,  num_workers=4)\n",
    "\n",
    "#check dataset\n",
    "print(dataset)\n",
    "print(dataset.class_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train function\n",
    "def train(model, criterion, optimizer):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    total_correct = 0\n",
    "    \n",
    "    # Iterate over data\n",
    "    for inputs, labels in train_data_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # backward + optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # statistics\n",
    "        total_loss += loss.item()\n",
    "        total_correct += torch.sum(preds == labels.data)\n",
    "        \n",
    "    avg_loss = total_loss / len(train_data_loader)\n",
    "    accuracy = total_correct.double() / len(train_dataset) * 100\n",
    "\n",
    "    print('Training Accuracy: {:.4f}% Training Loss: {:.4f}'.format(accuracy, avg_loss))\n",
    "    return \n",
    "\n",
    "#validation function\n",
    "def valid(model, criterion):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    total_correct = 0\n",
    "    \n",
    "    # Iterate over data\n",
    "    for inputs, labels in val_data_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # forward\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # statistics\n",
    "        total_loss += loss.item()\n",
    "        total_correct += torch.sum(preds == labels.data)\n",
    "        \n",
    "    avg_loss = total_loss / len(val_data_loader)\n",
    "    accuracy = total_correct.double() / len(val_dataset) * 100\n",
    "\n",
    "    print('Validation Accuracy: {:.4f}% Validation Loss: {:.4f}'.format(accuracy, avg_loss))\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using gpu if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "#build your model here\n",
    "#model = models.resnet18(weights = models.ResNet18_Weights.DEFAULT)\n",
    "#model = models.resnet18()\n",
    "#model = models.resnet18(weights = models.ResNet18_Weights.IMAGENET1K_V1)\n",
    "#model = models.resnet34(weights = models.ResNet34_Weights.DEFAULT)\n",
    "#model = models.resnet34(weights = models.ResNet34_Weights.IMAGENET1K_V1)\n",
    "#model = models.resnet50(weights = models.ResNet50_Weights.DEFAULT)\n",
    "#model = models.resnet50(weights = models.ResNet50_Weights.IMAGENET1K_V2)\n",
    "#model = models.resnet101(weights = models.ResNet101_Weights.DEFAULT)\n",
    "#model = models.resnet101(weights = models.ResNet101_Weights.IMAGENET1K_V2)\n",
    "#model = models.resnet152(weights = models.ResNet152_Weights.DEFAULT)\n",
    "#model = models.resnet152(weights = models.ResNet152_Weights.IMAGENET1K_V2)\n",
    "\n",
    "model = models.swin_v2_s(weights=models.Swin_V2_S_Weights.DEFAULT)\n",
    "#model = models.swin_v2_t(weights = models.Swin_V2_T_Weights.DEFAULT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SwinTransformer(\n",
       "  (features): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))\n",
       "      (1): Permute()\n",
       "      (2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): SwinTransformerBlockV2(\n",
       "        (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ShiftedWindowAttentionV2(\n",
       "          (qkv): Linear(in_features=96, out_features=288, bias=True)\n",
       "          (proj): Linear(in_features=96, out_features=96, bias=True)\n",
       "          (cpb_mlp): Sequential(\n",
       "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=512, out_features=3, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.0, mode=row)\n",
       "        (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (0): Linear(in_features=96, out_features=384, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=384, out_features=96, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): SwinTransformerBlockV2(\n",
       "        (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ShiftedWindowAttentionV2(\n",
       "          (qkv): Linear(in_features=96, out_features=288, bias=True)\n",
       "          (proj): Linear(in_features=96, out_features=96, bias=True)\n",
       "          (cpb_mlp): Sequential(\n",
       "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=512, out_features=3, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.013043478260869565, mode=row)\n",
       "        (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (0): Linear(in_features=96, out_features=384, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=384, out_features=96, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): PatchMergingV2(\n",
       "      (reduction): Linear(in_features=384, out_features=192, bias=False)\n",
       "      (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): SwinTransformerBlockV2(\n",
       "        (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ShiftedWindowAttentionV2(\n",
       "          (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "          (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "          (cpb_mlp): Sequential(\n",
       "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=512, out_features=6, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.02608695652173913, mode=row)\n",
       "        (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (0): Linear(in_features=192, out_features=768, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=768, out_features=192, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): SwinTransformerBlockV2(\n",
       "        (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ShiftedWindowAttentionV2(\n",
       "          (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "          (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "          (cpb_mlp): Sequential(\n",
       "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=512, out_features=6, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.03913043478260869, mode=row)\n",
       "        (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (0): Linear(in_features=192, out_features=768, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=768, out_features=192, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (4): PatchMergingV2(\n",
       "      (reduction): Linear(in_features=768, out_features=384, bias=False)\n",
       "      (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): SwinTransformerBlockV2(\n",
       "        (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ShiftedWindowAttentionV2(\n",
       "          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (cpb_mlp): Sequential(\n",
       "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.05217391304347826, mode=row)\n",
       "        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): SwinTransformerBlockV2(\n",
       "        (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ShiftedWindowAttentionV2(\n",
       "          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (cpb_mlp): Sequential(\n",
       "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.06521739130434782, mode=row)\n",
       "        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): SwinTransformerBlockV2(\n",
       "        (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ShiftedWindowAttentionV2(\n",
       "          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (cpb_mlp): Sequential(\n",
       "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.07826086956521738, mode=row)\n",
       "        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): SwinTransformerBlockV2(\n",
       "        (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ShiftedWindowAttentionV2(\n",
       "          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (cpb_mlp): Sequential(\n",
       "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.09130434782608696, mode=row)\n",
       "        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): SwinTransformerBlockV2(\n",
       "        (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ShiftedWindowAttentionV2(\n",
       "          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (cpb_mlp): Sequential(\n",
       "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.10434782608695652, mode=row)\n",
       "        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): SwinTransformerBlockV2(\n",
       "        (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ShiftedWindowAttentionV2(\n",
       "          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (cpb_mlp): Sequential(\n",
       "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.11739130434782608, mode=row)\n",
       "        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): SwinTransformerBlockV2(\n",
       "        (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ShiftedWindowAttentionV2(\n",
       "          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (cpb_mlp): Sequential(\n",
       "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.13043478260869565, mode=row)\n",
       "        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): SwinTransformerBlockV2(\n",
       "        (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ShiftedWindowAttentionV2(\n",
       "          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (cpb_mlp): Sequential(\n",
       "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.14347826086956522, mode=row)\n",
       "        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): SwinTransformerBlockV2(\n",
       "        (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ShiftedWindowAttentionV2(\n",
       "          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (cpb_mlp): Sequential(\n",
       "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.15652173913043477, mode=row)\n",
       "        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): SwinTransformerBlockV2(\n",
       "        (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ShiftedWindowAttentionV2(\n",
       "          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (cpb_mlp): Sequential(\n",
       "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.16956521739130434, mode=row)\n",
       "        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): SwinTransformerBlockV2(\n",
       "        (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ShiftedWindowAttentionV2(\n",
       "          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (cpb_mlp): Sequential(\n",
       "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.1826086956521739, mode=row)\n",
       "        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): SwinTransformerBlockV2(\n",
       "        (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ShiftedWindowAttentionV2(\n",
       "          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (cpb_mlp): Sequential(\n",
       "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.1956521739130435, mode=row)\n",
       "        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (12): SwinTransformerBlockV2(\n",
       "        (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ShiftedWindowAttentionV2(\n",
       "          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (cpb_mlp): Sequential(\n",
       "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.20869565217391303, mode=row)\n",
       "        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (13): SwinTransformerBlockV2(\n",
       "        (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ShiftedWindowAttentionV2(\n",
       "          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (cpb_mlp): Sequential(\n",
       "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.2217391304347826, mode=row)\n",
       "        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (14): SwinTransformerBlockV2(\n",
       "        (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ShiftedWindowAttentionV2(\n",
       "          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (cpb_mlp): Sequential(\n",
       "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.23478260869565215, mode=row)\n",
       "        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (15): SwinTransformerBlockV2(\n",
       "        (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ShiftedWindowAttentionV2(\n",
       "          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (cpb_mlp): Sequential(\n",
       "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.24782608695652175, mode=row)\n",
       "        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (16): SwinTransformerBlockV2(\n",
       "        (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ShiftedWindowAttentionV2(\n",
       "          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (cpb_mlp): Sequential(\n",
       "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.2608695652173913, mode=row)\n",
       "        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (17): SwinTransformerBlockV2(\n",
       "        (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ShiftedWindowAttentionV2(\n",
       "          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (cpb_mlp): Sequential(\n",
       "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.27391304347826084, mode=row)\n",
       "        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (6): PatchMergingV2(\n",
       "      (reduction): Linear(in_features=1536, out_features=768, bias=False)\n",
       "      (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (7): Sequential(\n",
       "      (0): SwinTransformerBlockV2(\n",
       "        (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ShiftedWindowAttentionV2(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (cpb_mlp): Sequential(\n",
       "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=512, out_features=24, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.28695652173913044, mode=row)\n",
       "        (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): SwinTransformerBlockV2(\n",
       "        (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ShiftedWindowAttentionV2(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (cpb_mlp): Sequential(\n",
       "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=512, out_features=24, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.3, mode=row)\n",
       "        (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  (permute): Permute()\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (head): Linear(in_features=768, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[[[ 2.1654e-02, -2.6789e-02, -2.3035e-02, -2.9833e-02],\n",
       "          [ 1.3321e-02, -5.0797e-02,  4.4563e-02,  2.0402e-02],\n",
       "          [-1.8994e-02, -3.0538e-02,  5.6745e-02,  3.3531e-02],\n",
       "          [ 3.9754e-02, -2.9815e-02,  1.8103e-02,  5.3637e-03]],\n",
       "\n",
       "         [[-5.6664e-03, -4.7441e-02, -4.2096e-02, -7.7939e-02],\n",
       "          [-3.1016e-02, -6.0178e-02,  8.4583e-02,  9.1222e-03],\n",
       "          [-6.3308e-02,  2.4530e-03,  1.2256e-01,  3.7304e-02],\n",
       "          [ 2.6121e-02, -2.5962e-02,  3.2726e-02, -1.1806e-02]],\n",
       "\n",
       "         [[ 2.8203e-02,  1.2786e-02,  6.1337e-03, -1.0342e-02],\n",
       "          [ 1.6456e-03, -1.1992e-02,  4.6317e-02, -9.2886e-03],\n",
       "          [-3.2019e-02, -9.2724e-05,  4.9178e-02, -7.9906e-04],\n",
       "          [-1.1062e-03, -3.0253e-02, -1.1510e-04, -2.4908e-02]]],\n",
       "\n",
       "\n",
       "        [[[-5.7383e-03, -4.3338e-02, -5.0308e-02, -2.7943e-02],\n",
       "          [ 2.8659e-03, -2.1501e-02, -4.1131e-02, -7.7814e-03],\n",
       "          [ 1.9901e-02, -3.3662e-02, -3.1174e-02,  7.5468e-03],\n",
       "          [ 4.4610e-02,  4.2901e-03,  5.7507e-03,  3.4091e-02]],\n",
       "\n",
       "         [[ 3.2559e-02, -1.6947e-02, -2.6618e-02,  3.8600e-03],\n",
       "          [ 2.1266e-02, -2.2539e-02, -4.6892e-02,  6.7602e-03],\n",
       "          [ 4.1487e-02, -4.3040e-02, -4.3083e-02,  1.4948e-02],\n",
       "          [ 9.6995e-02,  3.0963e-02,  2.0467e-02,  5.2162e-02]],\n",
       "\n",
       "         [[ 1.0298e-02, -2.2485e-02, -2.4487e-02, -1.1578e-02],\n",
       "          [ 1.5726e-02, -1.1994e-02, -2.6988e-02, -6.7568e-03],\n",
       "          [ 3.0517e-02, -2.5384e-02, -3.1057e-02, -6.0624e-03],\n",
       "          [ 7.1311e-02,  2.3452e-02,  1.0083e-02,  2.4186e-02]]],\n",
       "\n",
       "\n",
       "        [[[ 2.2735e-02, -5.9210e-02,  2.0092e-02, -6.0776e-02],\n",
       "          [ 4.1429e-02, -1.0687e-01, -6.0750e-02,  8.7313e-02],\n",
       "          [ 2.3721e-03, -5.5953e-02,  4.9998e-02,  3.5152e-02],\n",
       "          [ 5.7143e-02,  1.5368e-03, -8.7903e-03,  1.4743e-02]],\n",
       "\n",
       "         [[ 2.9888e-02, -3.6152e-02,  1.0169e-01, -1.1281e-01],\n",
       "          [ 4.9591e-02, -1.1305e-01, -4.1401e-02,  3.7521e-02],\n",
       "          [ 2.4250e-02, -1.8152e-03,  1.1400e-01, -6.5123e-02],\n",
       "          [ 9.7360e-02,  2.6021e-02, -2.6623e-02, -8.1265e-02]],\n",
       "\n",
       "         [[ 2.8183e-04,  2.1825e-02,  1.0685e-01, -1.3256e-02],\n",
       "          [-2.8969e-02, -2.0798e-02,  2.9839e-02,  3.0432e-02],\n",
       "          [-4.7879e-02,  1.8816e-03,  6.0248e-02, -3.1630e-02],\n",
       "          [-1.2008e-02, -1.6383e-02, -2.4328e-02, -4.0026e-02]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[-5.8977e-02, -1.1406e-01,  1.7083e-02, -8.9338e-02],\n",
       "          [ 2.5762e-02,  1.1375e-01,  4.1102e-02, -6.9622e-02],\n",
       "          [-3.6153e-02,  7.2422e-02,  3.5981e-02, -3.8768e-02],\n",
       "          [ 1.8405e-02,  4.7608e-02,  3.4411e-02, -2.2287e-02]],\n",
       "\n",
       "         [[-1.1643e-02, -7.2202e-02,  1.7180e-01,  3.7355e-02],\n",
       "          [ 1.6751e-02,  9.7557e-02,  4.4303e-02,  2.9349e-03],\n",
       "          [-1.3416e-01, -4.3533e-02, -5.2062e-02,  1.0275e-02],\n",
       "          [-2.4212e-02, -3.0829e-02, -1.1140e-02,  4.3074e-03]],\n",
       "\n",
       "         [[ 3.1535e-02, -4.4959e-02,  4.0918e-02, -7.1160e-03],\n",
       "          [ 4.9746e-02,  3.4234e-04, -4.3771e-02, -2.5184e-02],\n",
       "          [ 8.8667e-03, -2.3430e-02, -5.6833e-02, -1.6090e-02],\n",
       "          [ 5.3325e-02,  2.9053e-02,  1.6208e-02,  1.2899e-02]]],\n",
       "\n",
       "\n",
       "        [[[ 7.8742e-03,  1.3393e-01,  1.1073e-02, -8.6862e-02],\n",
       "          [ 1.2962e-01, -3.7172e-02,  2.2606e-02, -1.1074e-01],\n",
       "          [-9.3377e-02,  3.8046e-03,  5.0224e-03, -3.1041e-02],\n",
       "          [ 3.1454e-02, -1.0544e-01,  6.3496e-02,  3.2388e-02]],\n",
       "\n",
       "         [[-1.1993e-01,  8.4427e-02,  2.4083e-02, -4.3061e-02],\n",
       "          [ 1.1047e-01, -6.2506e-02,  5.8019e-02,  1.0057e-02],\n",
       "          [-6.8097e-02,  7.9799e-02, -2.1633e-02, -4.0628e-04],\n",
       "          [ 8.9662e-02, -1.1143e-01, -2.8458e-02,  9.3132e-03]],\n",
       "\n",
       "         [[-1.0143e-01, -1.4062e-02,  4.8494e-03,  4.0217e-02],\n",
       "          [ 1.1658e-02, -5.5500e-02,  2.4201e-02,  8.7270e-02],\n",
       "          [-7.3821e-03,  5.1366e-02, -2.4408e-02,  2.3176e-02],\n",
       "          [ 5.7273e-02, -1.3411e-02, -4.6578e-02, -1.1646e-02]]],\n",
       "\n",
       "\n",
       "        [[[-1.1471e-03, -2.0490e-02, -1.3384e-02, -1.1299e-03],\n",
       "          [ 5.3339e-02,  5.5301e-02, -3.2280e-02,  1.1421e-02],\n",
       "          [ 1.1666e-01,  1.4398e-02, -5.6247e-02, -1.2905e-01],\n",
       "          [ 1.2784e-01, -2.0061e-02, -3.1423e-02, -9.7083e-02]],\n",
       "\n",
       "         [[-7.9016e-02, -1.0699e-02, -6.7249e-02,  7.9861e-04],\n",
       "          [-7.7574e-02,  8.5246e-02, -2.6538e-02,  8.2576e-02],\n",
       "          [-7.9452e-02, -2.1523e-02,  4.6635e-02,  3.3219e-03],\n",
       "          [ 3.6317e-02, -4.9465e-02,  1.1592e-01,  5.4122e-02]],\n",
       "\n",
       "         [[ 1.8946e-02,  7.8424e-02, -6.7750e-03, -1.5762e-02],\n",
       "          [-4.9130e-03,  8.0419e-02, -1.3161e-02, -1.3027e-02],\n",
       "          [-6.9373e-02, -1.8972e-02,  2.4964e-02, -4.3081e-03],\n",
       "          [-3.8915e-02, -6.4076e-02,  4.7761e-02,  1.6683e-02]]]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.features[0][0].weight\n",
    "#model.conv1.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------start training--------------\n",
      "epoch: 1\n",
      "Training Accuracy: 47.5354% Training Loss: 1.9278\n",
      "Validation Accuracy: 85.4545% Validation Loss: 0.4836\n",
      "model saved\n",
      "epoch: 2\n",
      "Training Accuracy: 92.2350% Training Loss: 0.2746\n",
      "Validation Accuracy: 95.7576% Validation Loss: 0.1392\n",
      "model saved\n",
      "epoch: 3\n",
      "Training Accuracy: 96.0162% Training Loss: 0.1340\n",
      "Validation Accuracy: 95.7576% Validation Loss: 0.1188\n",
      "model saved\n",
      "epoch: 4\n",
      "Training Accuracy: 97.2991% Training Loss: 0.0941\n",
      "Validation Accuracy: 95.1515% Validation Loss: 0.0964\n",
      "epoch: 5\n",
      "Training Accuracy: 98.1769% Training Loss: 0.0563\n",
      "Validation Accuracy: 95.7576% Validation Loss: 0.1093\n",
      "model saved\n",
      "epoch: 6\n",
      "Training Accuracy: 98.9196% Training Loss: 0.0351\n",
      "Validation Accuracy: 96.9697% Validation Loss: 0.1162\n",
      "model saved\n",
      "epoch: 7\n",
      "Training Accuracy: 99.5949% Training Loss: 0.0176\n",
      "Validation Accuracy: 96.3636% Validation Loss: 0.1309\n",
      "epoch: 8\n",
      "Training Accuracy: 99.6624% Training Loss: 0.0137\n",
      "Validation Accuracy: 96.9697% Validation Loss: 0.1244\n",
      "model saved\n",
      "epoch: 9\n",
      "Training Accuracy: 99.7299% Training Loss: 0.0122\n",
      "Validation Accuracy: 96.9697% Validation Loss: 0.1427\n",
      "model saved\n",
      "epoch: 10\n",
      "Training Accuracy: 99.8650% Training Loss: 0.0078\n",
      "Validation Accuracy: 96.9697% Validation Loss: 0.1648\n",
      "model saved\n",
      "epoch: 11\n",
      "Training Accuracy: 99.5273% Training Loss: 0.0118\n",
      "Validation Accuracy: 96.9697% Validation Loss: 0.1646\n",
      "model saved\n",
      "epoch: 12\n",
      "Training Accuracy: 99.8650% Training Loss: 0.0063\n",
      "Validation Accuracy: 96.3636% Validation Loss: 0.1288\n",
      "epoch: 13\n",
      "Training Accuracy: 99.7299% Training Loss: 0.0061\n",
      "Validation Accuracy: 96.9697% Validation Loss: 0.1275\n",
      "model saved\n",
      "epoch: 14\n",
      "Training Accuracy: 99.9325% Training Loss: 0.0037\n",
      "Validation Accuracy: 96.3636% Validation Loss: 0.1372\n",
      "epoch: 15\n",
      "Training Accuracy: 99.9325% Training Loss: 0.0031\n",
      "Validation Accuracy: 96.9697% Validation Loss: 0.1857\n",
      "model saved\n",
      "epoch: 16\n",
      "Training Accuracy: 99.8650% Training Loss: 0.0096\n",
      "Validation Accuracy: 96.9697% Validation Loss: 0.2308\n",
      "model saved\n",
      "epoch: 17\n",
      "Training Accuracy: 99.7974% Training Loss: 0.0076\n",
      "Validation Accuracy: 96.9697% Validation Loss: 0.2691\n",
      "model saved\n",
      "epoch: 18\n",
      "Training Accuracy: 99.9325% Training Loss: 0.0098\n",
      "Validation Accuracy: 96.3636% Validation Loss: 0.2304\n",
      "epoch: 19\n",
      "Training Accuracy: 99.6624% Training Loss: 0.0117\n",
      "Validation Accuracy: 96.9697% Validation Loss: 0.1548\n",
      "model saved\n",
      "epoch: 20\n",
      "Training Accuracy: 99.3923% Training Loss: 0.0165\n",
      "Validation Accuracy: 96.9697% Validation Loss: 0.1779\n",
      "model saved\n",
      "epoch: 21\n",
      "Training Accuracy: 99.5273% Training Loss: 0.0118\n",
      "Validation Accuracy: 95.7576% Validation Loss: 0.1495\n",
      "epoch: 22\n",
      "Training Accuracy: 99.9325% Training Loss: 0.0040\n",
      "Validation Accuracy: 96.3636% Validation Loss: 0.1890\n",
      "epoch: 23\n",
      "Training Accuracy: 99.8650% Training Loss: 0.0068\n",
      "Validation Accuracy: 96.3636% Validation Loss: 0.2459\n",
      "epoch: 24\n",
      "Training Accuracy: 99.6624% Training Loss: 0.0134\n",
      "Validation Accuracy: 96.9697% Validation Loss: 0.2250\n",
      "model saved\n",
      "epoch: 25\n"
     ]
    }
   ],
   "source": [
    "####################  implement your optimizer ###################################\n",
    "## you can use any training methods if you want (ex:lr decay, weight decay.....)\n",
    "learning_rate = 0.00001\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate, betas = (0.99,0.999), weight_decay = 0.00001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "epochs = 100\n",
    "\n",
    "# start training\n",
    "model.to(device=device)\n",
    "acc_best = 0.0\n",
    "\n",
    "print('--------------start training--------------')\n",
    "for epoch in range(1, epochs+1):\n",
    "    \n",
    "    print('epoch:', epoch)\n",
    "    train(model, criterion, optimizer)\n",
    "    accuracy = valid(model, criterion)\n",
    "    writer.add_scalar('Learning_rate', learning_rate, epoch)\n",
    "    writer.add_histogram('Weights', model.features[0][0].weight, epoch)\n",
    "    writer.add_histogram('Gradients', model.features[0][0].weight.grad, epoch)\n",
    "    '''for tag, value in model.named_parameters():\n",
    "        writer.add_histogram('Gradients', value.grad, epoch)'''\n",
    "    if accuracy >= acc_best:\n",
    "        acc_best = accuracy\n",
    "        print(\"model saved\")\n",
    "        torch.save(model, \"model.pth\")\n",
    "    #learning_rate *= 0.98"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_test = transforms.Compose([transforms.Resize((img_size,img_size)),\n",
    "                                    transforms.ToTensor()\n",
    "                                    ])\n",
    "\n",
    "dataset_test = datasets.ImageFolder(root=data_path_test, transform=transform_test)\n",
    "dataloader_test  = data.DataLoader(dataset_test, batch_size=8, shuffle=False, num_workers=4) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model so that you don't need to train the model again\n",
    "test_model = torch.load(\"model.pth\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        bs = dataloader_test.batch_size\n",
    "        result = []\n",
    "        for i, (data, target) in enumerate(dataloader_test):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            _, preds = torch.max(output, 1, keepdim=True)\n",
    "            \n",
    "            arr = preds.data.cpu().numpy()\n",
    "            for j in range(preds.size()[0]):\n",
    "                file_name = dataset_test.samples[i*bs+j][0].split('/')[-1]\n",
    "                result.append((file_name,preds[j].cpu().numpy()[0]))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = test(test_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open ('ID_result.csv','w') as f:\n",
    "    f.write('ID,label\\n')\n",
    "    for data in result:\n",
    "        f.write(data[0]+','+str(data[1])+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
